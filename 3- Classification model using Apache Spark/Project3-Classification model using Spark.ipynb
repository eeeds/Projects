{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pyspark.sql import SQLContext\r\n",
    "from pyspark.sql import DataFrameNaFunctions\r\n",
    "from pyspark.ml import Pipeline\r\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\r\n",
    "from pyspark.ml.feature import Binarizer\r\n",
    "from pyspark.context import SparkContext\r\n",
    "from pyspark import SparkConf\r\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\r\n",
    "sqlContext = SQLContext(sc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = sqlContext.read.load('datasets/daily_weather.csv',\r\n",
    "                             format = 'com.databricks.spark.csv',\r\n",
    "                             header = 'true', inferSchema = 'true')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['number',\n",
       " 'air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "featureColumns = ['air_pressure_9am',\r\n",
    "                 'air_temp_9am', 'avg_wind_direction_9am','avg_wind_speed_9am',\r\n",
    "                 'max_wind_direction_9am','max_wind_speed_9am','rain_accumulation_9am',\r\n",
    "                 'rain_duration_9am']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = df.drop('number')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = df.na.drop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df.count(), len(df.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1064, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Se elige un treshold para la selección de una clase.\r\n",
    "binarizer = Binarizer(threshold = 24.99999, inputCol = 'relative_humidity_3pm',\r\n",
    "                     outputCol = 'label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "binarizedDF = binarizer.transform(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "binarizedDF.select('relative_humidity_3pm', 'label').show(4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------+-----+\n",
      "|relative_humidity_3pm|label|\n",
      "+---------------------+-----+\n",
      "|   36.160000000000494|  1.0|\n",
      "|     19.4265967985621|  0.0|\n",
      "|   14.460000000000045|  0.0|\n",
      "|   12.742547353761848|  0.0|\n",
      "+---------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Agregar características que usaremos para hacer predicciones en una sola columna\r\n",
    "assembler = VectorAssembler(inputCols = featureColumns,\r\n",
    "                           outputCol = 'features')\r\n",
    "\r\n",
    "assembled = assembler.transform(binarizedDF)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "assembled.select('relative_humidity_3pm','label').show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------+-----+\n",
      "|relative_humidity_3pm|label|\n",
      "+---------------------+-----+\n",
      "|   36.160000000000494|  1.0|\n",
      "|     19.4265967985621|  0.0|\n",
      "|   14.460000000000045|  0.0|\n",
      "|   12.742547353761848|  0.0|\n",
      "|    76.74000000000046|  1.0|\n",
      "|   33.930000000000256|  1.0|\n",
      "|   21.385656725200974|  0.0|\n",
      "|    74.92000000000041|  1.0|\n",
      "|   24.030000000000427|  0.0|\n",
      "|     68.0500000000012|  1.0|\n",
      "|    32.13000000000024|  1.0|\n",
      "|     79.0900000000002|  1.0|\n",
      "|    58.43000000000119|  1.0|\n",
      "|   27.990000000000173|  1.0|\n",
      "|   24.369999999999948|  0.0|\n",
      "|   14.801705962979918|  0.0|\n",
      "|    20.75568332171184|  0.0|\n",
      "|    45.87000000000005|  1.0|\n",
      "|    7.740000000000088|  0.0|\n",
      "|   14.649909361535952|  0.0|\n",
      "+---------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#Dividiendo el data en train and test\r\n",
    "\r\n",
    "(trainingData, testData) = assembled.randomSplit([0.8,0.2], seed = 13234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "trainingData.count(), testData.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(846, 218)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "dt = DecisionTreeClassifier(labelCol = 'label', \r\n",
    "                           featuresCol = 'features',\r\n",
    "                           maxDepth = 5,\r\n",
    "                           minInstancesPerNode = 20,\r\n",
    "                           impurity = 'gini')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pipeline = Pipeline(stages=[dt])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = pipeline.fit(trainingData)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#Making predictions\r\n",
    "predictions = model.transform(testData)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "predictions.select('prediction', 'label').show(20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Guardando las predicciones, tiene problemas en windows\r\n",
    "#predictions.select(\"prediction\", \"label\").write.save(path= 'predictions.csv', format = \"com.databricks.spark.csv\", header = 'true')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol = \"prediction\", metricName = 'accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#Accuracy\r\n",
    "evaluator.evaluate(predictions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7844036697247706"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# The MulticlassMetrics class can be used to generate a confusion matrix of our classifier model. However, unlike MulticlassClassificationEvaluator,\r\n",
    "#MulticlassMetrics works with RDDs of numbers and not DataFrames, so we need to convert our predictions DataFrame into an RDD.\r\n",
    "#If we use the rdd attribute of predictions, we see this is an RDD of Row\r\n",
    "#predictions.rdd.take(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#Instead, we can map the RDD to tuple to get an RDD of numbers:\r\n",
    "\r\n",
    "#predictions.rdd.map(tuple).take(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "#Let's create an instance of MulticlassMetrics with this RDD:\r\n",
    "#metrics = MulticlassMetrics(predictions.rdd.map(tuple))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "#The confusionMatrix() function returns a Spark Matrix, which we can convert to a Python Numpy array, and transpose to view\r\n",
    "#metrics.confusionMatrix().toArray().transpose()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}